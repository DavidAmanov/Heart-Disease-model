# -*- coding: utf-8 -*-
"""Untitled17.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Xwjf77MYhWeumip964fNQluHHaeO2Dk6
"""

#Цель проекта - построить доступную для развертывания (простую) модель, которая могла бы упростить диспанцеризацию и медецинское обслуживаное пациентов, а также повысить качество и
#скорость медицинского обслуживания для граждан. В качестве модели будем строить модель предсказывающую вероятность сердечно-сосудистых заболеваний для всех категорий граждан.
#Возьмем данные с сайта кегл, максимально большой датасет с понятными для исследователя данными и обработаем их.

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
import warnings
import seaborn as sb
warnings.filterwarnings('ignore')

data= pd.read_csv("/content/heart_2022_Key_indicators.csv")
data.head()

#Информация представленная в столбце:
#HeartDisease	-Болезь сердца (ишемической болезни сердца (ИБС) или инфаркта миокарда (ИМ))
#BMI - индекс мыссы тела (<16 - сильная худоба; 16-16,9 - умеренная худоба; 17-18,4 - легкая худоба; 18,5-24,9 - нормальный диапазон;
#25-29,9 - предожирение; 30-34,9 - ожирение первого класса; 35-39,9 - ожирение второго класса; 40> - ожирение 3 класс.)
#Smoking	- курит ли человек (да если за всю жизнь выкурил больше 5 пачек сигарет, если меньше то нет)
#AlcoholDrinking	- употребляет ли алкоголь (для мужчин да если больше 14 рюмок в неделю, для женщин если больше 7 рюмок в неделю)
#Stroke	- был ли инсульт
#PhysicalHealth	- физическое здоровье (сколько дней из последних 30 ваше здоровье было не удовлетворительным)
#MentalHealth	- ментальное здоровье (сколько дней из последних 30 ваше здоровье было не удовлетворительным)
#DiffWalking	- ходит ли человек с трудом по лестнице или нет
#Sex	- пол
#AgeCategory - возраст
#Race	- расса
#Diabetic	- наличие диабета
#PhysicalActivity	- физическая активность
#GenHealth	- генетическое здоровье
#SleepTime	- время сна
#Asthma	- наличие астмы
#KidneyDisease	- болезни почек
#SkinCancer - наличие рака кожи

data.info()

#Проведем анализ данных в таблице чтобы понять, какие в среднем люди принимали участие в выборке.

data.describe().T

fig_Sex = px.pie(data,names='Sex',title='Sex',color_discrete_sequence=px.colors.sequential.Aggrnyl)
fig_Sex.show()

fig_HeartDisease = px.pie(data,names='HeartDisease',title='HeartDisease',color_discrete_sequence=px.colors.sequential.Aggrnyl)
fig_HeartDisease.show()

fig_AlcoholDrinking= px.pie(data,names='AlcoholDrinking',title='AlcoholDrinking',color_discrete_sequence=px.colors.sequential.Aggrnyl)
fig_AlcoholDrinking.show()

fig_Stroke = px.pie(data,names='Stroke',title='Stroke',color_discrete_sequence=px.colors.sequential.Aggrnyl)
fig_Stroke.show()

fig_DiffWalking = px.pie(data,names='DiffWalking',title='DiffWalking',color_discrete_sequence=px.colors.sequential.Aggrnyl)
fig_DiffWalking.show()

fig_smoking = px.pie(data,names='Smoking',title='Smoking',color_discrete_sequence=px.colors.sequential.Aggrnyl)
fig_smoking.show()

fig_Diabetic = px.pie(data,names='Diabetic',title='Diabetic',color_discrete_sequence=px.colors.sequential.Aggrnyl)
fig_Diabetic.show()

fig_PhysicalActivity = px.pie(data,names='PhysicalActivity',title='PhysicalActivity',color_discrete_sequence=px.colors.sequential.Aggrnyl)
fig_PhysicalActivity.show()

fig_GenHealth = px.pie(data,names='GenHealth',title='GenHealth',color_discrete_sequence=px.colors.sequential.Aggrnyl)
fig_GenHealth.show()

fig_Asthma = px.pie(data,names='Asthma',title='Asthma',color_discrete_sequence=px.colors.sequential.Aggrnyl)
fig_Asthma.show()

fig_KidneyDisease = px.pie(data,names='KidneyDisease',title='KidneyDisease',color_discrete_sequence=px.colors.sequential.Aggrnyl)
fig_KidneyDisease.show()

fig_SkinCancer = px.pie(data,names='SkinCancer',title='SkinCancer',color_discrete_sequence=px.colors.sequential.Aggrnyl)
fig_SkinCancer.show()

#Предполагаем, что чем больше индекс мыссы тела тем больше шанс сердченых заболеваний, однако на графике это не очень видно.
BMI = sns.displot(data, x="BMI", col="HeartDisease")

#Посмотрим влияет ли возраст, как видно из графика - да влияет.
plt.figure(figsize = (12,3))
sb.countplot(x= data['AgeCategory'].sort_values(ascending=True), hue = 'HeartDisease', data = data)

stroke = sb.countplot(x= data['Stroke'], hue = 'HeartDisease', data = data)

plt.figure(figsize = (10,3))
sb.countplot(x= data['Diabetic'], hue = 'HeartDisease', data = data)

plt.figure(figsize = (10,3))
sb.countplot(x= data['SkinCancer'], hue = 'HeartDisease', data = data)

plt.figure(figsize = (10,3))
sb.countplot(x= data['Asthma'], hue = 'HeartDisease', data = data)

plt.figure(figsize = (10,3))
sb.countplot(x= data['PhysicalActivity'], hue = 'HeartDisease', data = data)

plt.figure(figsize = (10,3))
sb.countplot(x= data['DiffWalking'], hue = 'HeartDisease', data = data)

plt.figure(figsize = (10,3))
sb.countplot(x= data['GenHealth'].sort_values(ascending=True), hue = 'HeartDisease', data = data)

#Из полученных данных можно сделать следующие выводы:
#1 - выборку представленную в датасете можно считать равной по половому признаку(значит построенная модель будет работать
#    в одинаковой степени как для женщин, так и для мужчин)
#2 - у большинства людей предствелнных в выборке нет каких-либо хронических заболеваний, злоупотребления алкоголем или жалоб на психологическое
#    состояние. Однако около половины из них за жизнь курили или курят в данный момент(41,2%)
#3 - 8,5% из опрошеных имеют болезни сердца.
#4 - с возрастом риск болезней сердца увеличивается, также судя по графику инсульта он увеличивает риск болезней сердца в последующем,
#    аналогично это касается и диабета и проблем с физической активностью
#    (вполне возможно что проблемы с сердцем вызывают все эти заболевания и трудности, а не наоборот)
#5 - Возможным однозначным признаком проблем с сердцем в будущем является генетическое здоровье, по графику около половины из тех у кого оно низкое
#    имеют проблемы с сердцем, гены у нас с самого рождения и не могут стать последствием инфаркта, как отдышка например.
#6 - Для построения модели предсказывающей будущие пробелмы со здоровьем, нужно дать модели данные в пропорции 50% - не имеющих проблем,
#    50 - имеющие проблемы, для того чтобы модель лучше обучалась
#

#Сделаем копию датасета для дальнейших манипуляций.
df=data.copy()

#Небольшое изучение Википедии подсказывает, что из даного дата сета можно построить не только модель предсказывающую риск инфаркта и ишемической болезни сердца
#но и риск инсульта в будущем, так как перенесенный инфаркт является фактором риска инсульта в последующем, помимо этого факторами риска являются также диабет,
#малоподвижный образ жизни и курение

#Построение модели предсказания проблем с сердцем:
#Разделим данные так, чтобы 50% человек не имели проблем с сердцем и 50% имели эти проблемы.

count_class_no, count_class_yes = df['HeartDisease'].value_counts()
df_class_yes = df[df['HeartDisease'] == 'Yes']
df_class_no = df[df['HeartDisease'] == 'No']
df_class_no_under = df_class_no.sample(count_class_yes)
df_test_under = pd.concat([df_class_no_under, df_class_yes], axis=0)
print('Случайное распределение по признаку "да" - "нет"')
print(df_test_under['HeartDisease'].value_counts())
df_test_under['HeartDisease'].value_counts().plot(kind='bar', title='Count (HeartDisease)', color=['y', 'b'])

#Отбросим ненужные столбы "пол" и "раса", а также сделаем перевод из категориальных признаков в числовые

df_test_under = df_test_under.drop(columns='Race')
df_test_under = df_test_under.drop(columns='Sex')
df_test_under.head()

df_test_under.loc[[280660]]

#Преобразуем категореальные признаки в числовые для работы с будущей моделью
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
cols = ['HeartDisease', 'Smoking', 'AlcoholDrinking','Stroke','DiffWalking','AgeCategory','Diabetic','PhysicalActivity','GenHealth','Asthma','KidneyDisease','SkinCancer']

df_test_under[cols] = df_test_under[cols].apply(LabelEncoder().fit_transform)
df_test_under.info()

from sklearn.model_selection import train_test_split
x=df_test_under.drop('HeartDisease', axis=1).values
y=df_test_under['HeartDisease'].values
x_train ,x_test ,y_train ,y_test=train_test_split(x,y ,test_size=0.25,random_state=42)

from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(n_estimators= 5 , max_depth= 3 , max_features=4)
rf.fit(x_train , y_train)
rf.score(x_train , y_train)

r=rf.score(x_test,y_test)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
pred = rf.predict(x_test)
metric_names = ["Accuracy", "Precision", "Recall", "F1 Score"]

def measures(preds):
    acc = accuracy_score(y_test, preds)
    pre = precision_score(y_test, preds)
    rec = recall_score(y_test, preds)
    f1_ = f1_score(y_test, preds)
    cm = confusion_matrix(y_test, preds)
    return [acc, pre, rec, f1_]

rf_scores = measures(pred)
cm = confusion_matrix(pred, y_test)

print("RandomForestClassifier : \n")
for i, name in enumerate(metric_names):
    print(f"\t{name:10}  : {rf_scores[i]:.4f}")
print(f"\nConfusion Matrix : \n")

fig = px.imshow(cm, text_auto=True, color_continuous_scale='fall', width=400, height=400)
fig.show()

#Теперь сделаем модель логистической регрессии

from sklearn.linear_model import LogisticRegression
lr = LogisticRegression(penalty='l2' , C=0.5)
lr.fit(x_train , y_train )
lr.score(x_train , y_train)

l=lr.score(x_test,y_test)

pred_lr = lr.predict(x_test)
metric_names = ["Accuracy", "Precision", "Recall", "F1 Score"]
lr_scores = measures(pred_lr)
cm_lr = confusion_matrix(pred_lr, y_test)

print("Logistic Regression : \n")
for i, name in enumerate(metric_names):
    print(f"\t{name:10}  : {lr_scores[i]:.4f}")
print(f"\nConfusion Matrix : \n")

fig = px.imshow(cm_lr, text_auto=True, color_continuous_scale='fall', width=400, height=400)
fig.show()

#Модель SGDClassifier

from sklearn.linear_model import  SGDClassifier
sgd = SGDClassifier()
sgd.fit(x_train, y_train)
sgd.score(x_train , y_train)

s=sgd.score(x_test,y_test)

# Прогноз
pred_sgd = sgd.predict(x_test)


sgd_scores = measures(pred_sgd)
cm_sgd = confusion_matrix(pred_sgd, y_test)


print("SGD Classifier : \n")
for i, name in enumerate(metric_names):
    print(f"\t{name:10}  : {sgd_scores[i]:.4f}")
print(f"\nConfusion Matrix : \n")

fig = px.imshow(cm_sgd, text_auto=True, color_continuous_scale='fall', width=400, height=400)
fig.show()

#Модель GaussianNB

from sklearn.naive_bayes import GaussianNB
gnb = GaussianNB()
gnb.fit(x_train,y_train)
gnb.score(x_train,y_train)

g=gnb.score(x_test,y_test)

pred_gnb = gnb.predict(x_test)


gnb_scores = measures(pred_gnb)
cm_gnb = confusion_matrix(pred_gnb, y_test)


print("GNB Classifier : \n")
for i, name in enumerate(metric_names):
    print(f"\t{name:10}  : {gnb_scores[i]:.4f}")
print(f"\nConfusion Matrix : \n")

fig = px.imshow(cm_gnb, text_auto=True, color_continuous_scale='fall', width=400, height=400)
fig.show()

#Сравним полученные модели
model_names = ["RF", "LR", "SGDC", "GNB"]

accs = np.array([rf_scores[0], lr_scores[0], sgd_scores[0], gnb_scores[0]])
pres = np.array([rf_scores[1], lr_scores[1], sgd_scores[1], gnb_scores[1]])
recs = np.array([rf_scores[2], lr_scores[2], sgd_scores[2], gnb_scores[2]])
f1s = np.array([rf_scores[3], lr_scores[3], sgd_scores[3], gnb_scores[3]])

fig = px.bar(x=model_names, y=recs, title="Recall", color=model_names)
fig.show()

fig = px.bar(x=model_names, y=pres, title="Precision", color=model_names)
fig.show()

fig = px.bar(x=model_names, y=accs, title="Accuracy", color=model_names)
fig.show()

fig = px.bar(x=model_names, y=f1s, title="F1", color=model_names)
fig.show()

R2 = np.array([r, l, s, g])
fig = px.bar(x=model_names, y=R2, title="R2", color=model_names)
fig.show()

#Анализ моделей показывает, что модели RF LR и SGDC близки по своим значеняим, в данном датасете важной характеристикой будет показатель Reccal, т.к.
#он указывает на количество ложных пропусков (FN), то есть нам лучше будет у здорового человека предположить что он болеет и на следуещем этапе исследования
#выяснить что он не болеет, чем пропустить больного человека и посчитать что он здоровый, чем больше Reccal тем меньше больных людей мы будем ошибочно
#считать здоровыми и по данной характеристике лучше себя показывает модель SGDC, также у нее лучше коэффициент детерменации R2 и доля правильных ответов (Acc)

#Сохраним полученную  лучшую модель
import pickle
with open('model.pkl','wb') as f:
    pickle.dump(sgd,f)

#Полученную модель в дальнейшем можно реализовать как бота в телеграмме у любой медицинской организации или разввернуть ее на сайте, где человек
#мог бы отвечая на простые вопросы о себе задуматься о состоянии своего здоровья. Для реализации подобного потребуется код, который будет переводить
#категориальные ответы пользователей в числовые для модели, прописать инструкцию для пользователей, что и зачем им нужно передавать боту или на сайт